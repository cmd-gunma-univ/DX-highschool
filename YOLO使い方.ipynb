{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmd-gunma-univ/DX-highschool/blob/main/YOLO%E4%BD%BF%E3%81%84%E6%96%B9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bac2c64-9aaf-4af4-9e9d-ec0c53aaa318",
      "metadata": {
        "id": "8bac2c64-9aaf-4af4-9e9d-ec0c53aaa318",
        "outputId": "a3259470-1c0a-44dc-e151-69106a48643f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â¹ æ‰‹å‹•ã§åœæ­¢ã—ã¾ã—ãŸã€‚\n",
            "ğŸ“¸ ã‚«ãƒ¡ãƒ©ã‚’è§£æ”¾ã—ã¾ã—ãŸã€‚\n"
          ]
        }
      ],
      "source": [
        "# USBã‚«ãƒ¡ãƒ©ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ’®å½±\n",
        "import cv2\n",
        "from IPython.display import display, Image, clear_output\n",
        "import time\n",
        "\n",
        "# 0 ã¯ã‚«ãƒ¡ãƒ©IDã€‚è¤‡æ•°æ¥ç¶šæ™‚ã¯ 1, 2 ã«å¤‰æ›´ã—ã¦è©¦ã—ã¦ãã ã•ã„\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# å¿…è¦ãªã‚‰è§£åƒåº¦æŒ‡å®šï¼ˆä»»æ„ï¼‰\n",
        "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
        "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
        "\n",
        "try:\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(\"ã‚«ãƒ¡ãƒ©ãŒé–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚/dev/video0 ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
        "            break\n",
        "\n",
        "        # Jupyterã§è¡¨ç¤ºï¼ˆcv2.imshowã¯ä½¿ã‚ãªã„ï¼‰\n",
        "        ok, jpg = cv2.imencode('.jpg', frame)\n",
        "        if not ok:\n",
        "            continue\n",
        "        clear_output(wait=True)\n",
        "        display(Image(data=jpg.tobytes()))\n",
        "        time.sleep(0.03)  # ç´„30fpsç›¸å½“ã®å¾…ã¡ï¼ˆèª¿æ•´å¯ï¼‰\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"â¹ æ‰‹å‹•ã§åœæ­¢ã—ã¾ã—ãŸã€‚\")\n",
        "\n",
        "finally:\n",
        "    cap.release()\n",
        "    print(\"ğŸ“¸ ã‚«ãƒ¡ãƒ©ã‚’è§£æ”¾ã—ã¾ã—ãŸã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dd247a9-815b-4c65-8930-139611e6e238",
      "metadata": {
        "id": "8dd247a9-815b-4c65-8930-139611e6e238"
      },
      "outputs": [],
      "source": [
        "# ç‰©ä½“æ¤œå‡º\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from IPython.display import display, Image, clear_output\n",
        "import time\n",
        "\n",
        "# --- YOLOãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ ---\n",
        "model = YOLO(\"yolov8n.pt\")  # è»½é‡ãƒ¢ãƒ‡ãƒ«ã€‚åˆå›å®Ÿè¡Œæ™‚ã«è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™\n",
        "\n",
        "# --- USBã‚«ãƒ¡ãƒ©ã‚’èµ·å‹• ---\n",
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"ã‚«ãƒ¡ãƒ©ãŒé–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚/dev/video0 ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
        "\n",
        "# è§£åƒåº¦è¨­å®šï¼ˆèª¿æ•´å¯èƒ½ï¼‰\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
        "            break\n",
        "\n",
        "        # --- YOLOv8ã§æ¨è«– ---\n",
        "        results = model.predict(source=frame, imgsz=640, conf=0.25, verbose=False)[0]\n",
        "\n",
        "        # --- ã€Œpersonã€ã‚¯ãƒ©ã‚¹ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆclass_id == 0ï¼‰---\n",
        "        person_count = sum(1 for box in results.boxes if int(box.cls[0]) == 0)\n",
        "\n",
        "        # --- çµæœã®æç”» ---\n",
        "        annotated = results.plot()\n",
        "        cv2.putText(annotated, f\"Persons: {person_count}\", (10, 40),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
        "\n",
        "        # --- Jupyterä¸Šã§è¡¨ç¤º ---\n",
        "        ok, jpg = cv2.imencode(\".jpg\", annotated)\n",
        "        if not ok:\n",
        "            continue\n",
        "        clear_output(wait=True)\n",
        "        display(Image(data=jpg.tobytes()))\n",
        "\n",
        "        time.sleep(0.05)  # è¡¨ç¤ºé–“éš”ï¼ˆfpsèª¿æ•´ï¼‰\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"â¹ æ‰‹å‹•ã§åœæ­¢ã—ã¾ã—ãŸã€‚\")\n",
        "\n",
        "finally:\n",
        "    cap.release()\n",
        "    print(\"ğŸ“¸ ã‚«ãƒ¡ãƒ©ã‚’è§£æ”¾ã—ã¾ã—ãŸã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cf6166a-0c96-4e61-92a6-cc8df1c5e098",
      "metadata": {
        "id": "5cf6166a-0c96-4e61-92a6-cc8df1c5e098"
      },
      "outputs": [],
      "source": [
        "# ãƒãƒ¼ã‚ºæ¤œå‡º\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2, time\n",
        "from IPython.display import display, Image, clear_output\n",
        "\n",
        "# --- ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆæœ€è»½é‡ãƒ¢ãƒ‡ãƒ«ï¼‰ ---\n",
        "model = YOLO(\"yolov8n-pose.pt\")  # ä»–: yolov8s-pose.pt ãªã©\n",
        "\n",
        "# --- ã‚«ãƒ¡ãƒ©èµ·å‹• ---\n",
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"ã‚«ãƒ¡ãƒ©ãŒé–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚/dev/video0 ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
        "\n",
        "# è§£åƒåº¦ï¼ˆè»½ãã—ãŸã„å ´åˆã¯ 640x480 ãªã©ã«ä¸‹ã’ã‚‹ï¼‰\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH,  640)\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
        "            break\n",
        "\n",
        "        # --- æ¨è«–ï¼ˆconfã‚„imgszã§è»½é‡åŒ–èª¿æ•´å¯ï¼‰ ---\n",
        "        # results = model(frame, imgsz=640, conf=0.25, stream=False)[0]\n",
        "        results = model.predict(source=frame, imgsz=640, conf=0.25, verbose=False)[0]\n",
        "\n",
        "        # --- éª¨æ ¼ã‚’æç”»ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ  ---\n",
        "        annotated = results.plot()\n",
        "\n",
        "        # --- Jupyterã§è¡¨ç¤º ---\n",
        "        ok, jpg = cv2.imencode(\".jpg\", annotated)\n",
        "        if not ok:\n",
        "            continue\n",
        "        clear_output(wait=True)\n",
        "        display(Image(data=jpg.tobytes()))\n",
        "\n",
        "        # è¡¨ç¤ºé–“éš”ï¼ˆé‡ã„ç’°å¢ƒã§ã¯ 0.1ï½0.2 ã«ï¼‰\n",
        "        time.sleep(0.03)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"â¹ æ‰‹å‹•ã§åœæ­¢ã—ã¾ã—ãŸã€‚\")\n",
        "\n",
        "finally:\n",
        "    cap.release()\n",
        "    print(\"ğŸ“¸ ã‚«ãƒ¡ãƒ©ã‚’è§£æ”¾ã—ã¾ã—ãŸã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7a4c860-031a-499f-8763-489f4bec56be",
      "metadata": {
        "id": "b7a4c860-031a-499f-8763-489f4bec56be"
      },
      "outputs": [],
      "source": [
        "# è¡¨æƒ…æ¤œå‡º\n",
        "import cv2\n",
        "from fer import FER\n",
        "from IPython.display import display, Image, clear_output\n",
        "import time\n",
        "\n",
        "# --- ã‚«ãƒ¡ãƒ©ã‚’é–‹ã ---\n",
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"ã‚«ãƒ¡ãƒ©ãŒé–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚/dev/video0 ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
        "\n",
        "# --- è¡¨æƒ…èªè­˜ãƒ¢ãƒ‡ãƒ« ---\n",
        "detector = FER()\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
        "            break\n",
        "\n",
        "        # --- è¡¨æƒ…æ¨å®š ---\n",
        "        result = detector.top_emotion(frame)\n",
        "        if result:\n",
        "            emotion, score = result\n",
        "            if emotion is not None and score is not None:\n",
        "                label = f\"{emotion} ({score:.2f})\"\n",
        "            else:\n",
        "                label = \"No face detected\"\n",
        "        else:\n",
        "            label = \"No face detected\"\n",
        "\n",
        "        # --- çµæœã‚’æç”» ---\n",
        "        cv2.putText(frame, label, (10, 50),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "\n",
        "        # --- Jupyterã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º ---\n",
        "        ok, jpg = cv2.imencode('.jpg', frame)\n",
        "        if not ok:\n",
        "            continue\n",
        "        clear_output(wait=True)\n",
        "        display(Image(data=jpg.tobytes()))\n",
        "\n",
        "        time.sleep(0.1)  # è¡¨ç¤ºé–“éš”ï¼ˆ0.03ã€œ0.2ã§èª¿æ•´ï¼‰\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"â¹ æ‰‹å‹•ã§åœæ­¢ã—ã¾ã—ãŸã€‚\")\n",
        "\n",
        "finally:\n",
        "    cap.release()\n",
        "    print(\"ğŸ“¸ ã‚«ãƒ¡ãƒ©ã‚’è§£æ”¾ã—ã¾ã—ãŸã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6fa963e-1f48-4d8c-be97-ed432061696e",
      "metadata": {
        "id": "b6fa963e-1f48-4d8c-be97-ed432061696e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}