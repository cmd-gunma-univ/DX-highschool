{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmd-gunma-univ/DX-highschool/blob/main/YOLO%E4%BD%BF%E3%81%84%E6%96%B9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bac2c64-9aaf-4af4-9e9d-ec0c53aaa318",
      "metadata": {
        "id": "8bac2c64-9aaf-4af4-9e9d-ec0c53aaa318",
        "outputId": "a3259470-1c0a-44dc-e151-69106a48643f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏹ 手動で停止しました。\n",
            "📸 カメラを解放しました。\n"
          ]
        }
      ],
      "source": [
        "# USBカメラでリアルタイム撮影\n",
        "import cv2\n",
        "from IPython.display import display, Image, clear_output\n",
        "import time\n",
        "\n",
        "# 0 はカメラID。複数接続時は 1, 2 に変更して試してください\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# 必要なら解像度指定（任意）\n",
        "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
        "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
        "\n",
        "try:\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(\"カメラが開けませんでした。/dev/video0 を確認してください。\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"フレームを取得できませんでした。\")\n",
        "            break\n",
        "\n",
        "        # Jupyterで表示（cv2.imshowは使わない）\n",
        "        ok, jpg = cv2.imencode('.jpg', frame)\n",
        "        if not ok:\n",
        "            continue\n",
        "        clear_output(wait=True)\n",
        "        display(Image(data=jpg.tobytes()))\n",
        "        time.sleep(0.03)  # 約30fps相当の待ち（調整可）\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"⏹ 手動で停止しました。\")\n",
        "\n",
        "finally:\n",
        "    cap.release()\n",
        "    print(\"📸 カメラを解放しました。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dd247a9-815b-4c65-8930-139611e6e238",
      "metadata": {
        "id": "8dd247a9-815b-4c65-8930-139611e6e238"
      },
      "outputs": [],
      "source": [
        "# 物体検出\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from IPython.display import display, Image, clear_output\n",
        "import time\n",
        "\n",
        "# --- YOLOモデルの読み込み ---\n",
        "model = YOLO(\"yolov8n.pt\")  # 軽量モデル。初回実行時に自動ダウンロードされます\n",
        "\n",
        "# --- USBカメラを起動 ---\n",
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"カメラが開けませんでした。/dev/video0 を確認してください。\")\n",
        "\n",
        "# 解像度設定（調整可能）\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"フレームを取得できませんでした。\")\n",
        "            break\n",
        "\n",
        "        # --- YOLOv8で推論 ---\n",
        "        results = model.predict(source=frame, imgsz=640, conf=0.25, verbose=False)[0]\n",
        "\n",
        "        # --- 「person」クラスをカウント（class_id == 0）---\n",
        "        person_count = sum(1 for box in results.boxes if int(box.cls[0]) == 0)\n",
        "\n",
        "        # --- 結果の描画 ---\n",
        "        annotated = results.plot()\n",
        "        cv2.putText(annotated, f\"Persons: {person_count}\", (10, 40),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
        "\n",
        "        # --- Jupyter上で表示 ---\n",
        "        ok, jpg = cv2.imencode(\".jpg\", annotated)\n",
        "        if not ok:\n",
        "            continue\n",
        "        clear_output(wait=True)\n",
        "        display(Image(data=jpg.tobytes()))\n",
        "\n",
        "        time.sleep(0.05)  # 表示間隔（fps調整）\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"⏹ 手動で停止しました。\")\n",
        "\n",
        "finally:\n",
        "    cap.release()\n",
        "    print(\"📸 カメラを解放しました。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cf6166a-0c96-4e61-92a6-cc8df1c5e098",
      "metadata": {
        "id": "5cf6166a-0c96-4e61-92a6-cc8df1c5e098"
      },
      "outputs": [],
      "source": [
        "# ポーズ検出\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2, time\n",
        "from IPython.display import display, Image, clear_output\n",
        "\n",
        "# --- モデル読み込み（最軽量モデル） ---\n",
        "model = YOLO(\"yolov8n-pose.pt\")  # 他: yolov8s-pose.pt など\n",
        "\n",
        "# --- カメラ起動 ---\n",
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"カメラが開けませんでした。/dev/video0 を確認してください。\")\n",
        "\n",
        "# 解像度（軽くしたい場合は 640x480 などに下げる）\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH,  640)\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"フレームを取得できませんでした。\")\n",
        "            break\n",
        "\n",
        "        # --- 推論（confやimgszで軽量化調整可） ---\n",
        "        # results = model(frame, imgsz=640, conf=0.25, stream=False)[0]\n",
        "        results = model.predict(source=frame, imgsz=640, conf=0.25, verbose=False)[0]\n",
        "\n",
        "        # --- 骨格を描画したフレーム ---\n",
        "        annotated = results.plot()\n",
        "\n",
        "        # --- Jupyterで表示 ---\n",
        "        ok, jpg = cv2.imencode(\".jpg\", annotated)\n",
        "        if not ok:\n",
        "            continue\n",
        "        clear_output(wait=True)\n",
        "        display(Image(data=jpg.tobytes()))\n",
        "\n",
        "        # 表示間隔（重い環境では 0.1～0.2 に）\n",
        "        time.sleep(0.03)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"⏹ 手動で停止しました。\")\n",
        "\n",
        "finally:\n",
        "    cap.release()\n",
        "    print(\"📸 カメラを解放しました。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7a4c860-031a-499f-8763-489f4bec56be",
      "metadata": {
        "id": "b7a4c860-031a-499f-8763-489f4bec56be"
      },
      "outputs": [],
      "source": [
        "# 表情検出\n",
        "import cv2\n",
        "from fer import FER\n",
        "from IPython.display import display, Image, clear_output\n",
        "import time\n",
        "\n",
        "# --- カメラを開く ---\n",
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"カメラが開けませんでした。/dev/video0 を確認してください。\")\n",
        "\n",
        "# --- 表情認識モデル ---\n",
        "detector = FER()\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"フレームを取得できませんでした。\")\n",
        "            break\n",
        "\n",
        "        # --- 表情推定 ---\n",
        "        result = detector.top_emotion(frame)\n",
        "        if result:\n",
        "            emotion, score = result\n",
        "            if emotion is not None and score is not None:\n",
        "                label = f\"{emotion} ({score:.2f})\"\n",
        "            else:\n",
        "                label = \"No face detected\"\n",
        "        else:\n",
        "            label = \"No face detected\"\n",
        "\n",
        "        # --- 結果を描画 ---\n",
        "        cv2.putText(frame, label, (10, 50),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "\n",
        "        # --- Jupyterでリアルタイム表示 ---\n",
        "        ok, jpg = cv2.imencode('.jpg', frame)\n",
        "        if not ok:\n",
        "            continue\n",
        "        clear_output(wait=True)\n",
        "        display(Image(data=jpg.tobytes()))\n",
        "\n",
        "        time.sleep(0.1)  # 表示間隔（0.03〜0.2で調整）\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"⏹ 手動で停止しました。\")\n",
        "\n",
        "finally:\n",
        "    cap.release()\n",
        "    print(\"📸 カメラを解放しました。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6fa963e-1f48-4d8c-be97-ed432061696e",
      "metadata": {
        "id": "b6fa963e-1f48-4d8c-be97-ed432061696e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}